2019-09-28 17:52:13,606 : Reward 0.0
2019-09-28 17:52:13,607 : Evaluation Reward 0.0 at step 10, run 0
2019-09-28 17:52:13,607 : Average Reward 0.0 at step 10, run 0
2019-09-28 17:52:13,609 : tderror_Q_U 0.0 at step 10
2019-09-28 17:52:13,609 : tderror_Q_Omega 0.0 at step 10
2019-09-28 17:52:13,615 : Reward 0.0
2019-09-28 17:52:13,615 : Evaluation Reward 0.0 at step 20, run 0
2019-09-28 17:52:13,615 : Average Reward 0.0 at step 20, run 0
2019-09-28 17:52:13,616 : tderror_Q_U 0.0 at step 20
2019-09-28 17:52:13,616 : tderror_Q_Omega 0.0 at step 20
2019-09-28 17:52:13,621 : Reward 0.0
2019-09-28 17:52:13,621 : Evaluation Reward 0.0 at step 30, run 0
2019-09-28 17:52:13,621 : Average Reward 0.0 at step 30, run 0
2019-09-28 17:52:13,622 : tderror_Q_U 0.0 at step 30
2019-09-28 17:52:13,622 : tderror_Q_Omega 0.0 at step 30
2019-09-28 17:52:13,626 : Reward 0.0
2019-09-28 17:52:13,627 : Evaluation Reward 0.0 at step 40, run 0
2019-09-28 17:52:13,627 : Average Reward 0.0 at step 40, run 0
2019-09-28 17:52:13,628 : tderror_Q_U 0.0 at step 40
2019-09-28 17:52:13,628 : tderror_Q_Omega 0.0 at step 40
2019-09-28 17:52:13,632 : Reward 0.0
2019-09-28 17:52:13,633 : Evaluation Reward 0.0 at step 50, run 0
2019-09-28 17:52:13,633 : Average Reward 0.0 at step 50, run 0
2019-09-28 17:52:13,634 : tderror_Q_U 0.0 at step 50
2019-09-28 17:52:13,634 : tderror_Q_Omega 0.0 at step 50
2019-09-28 17:52:13,638 : Reward 0.0
2019-09-28 17:52:13,639 : Evaluation Reward 0.0 at step 60, run 0
2019-09-28 17:52:13,639 : Average Reward 0.0 at step 60, run 0
2019-09-28 17:52:13,640 : tderror_Q_U 0.0 at step 60
2019-09-28 17:52:13,640 : tderror_Q_Omega 0.0 at step 60
2019-09-28 17:52:13,646 : Reward 0.0
2019-09-28 17:52:13,646 : Evaluation Reward 0.0 at step 70, run 0
2019-09-28 17:52:13,646 : Average Reward 0.0 at step 70, run 0
2019-09-28 17:52:13,647 : tderror_Q_U 0.0 at step 70
2019-09-28 17:52:13,647 : tderror_Q_Omega 0.0 at step 70
2019-09-28 17:52:13,651 : Average Duration of3.166666666666667 for run 0
2019-09-28 17:52:13,653 : Option Switches are 36 for run 0
2019-09-28 17:52:13,654 : tderror_Q_U 0.0 at step 1000
2019-09-28 17:52:13,654 : tderror_Q_Omega 0.0 at step 1000
2019-09-28 17:52:13,658 : Reward 0.0
2019-09-28 17:52:13,658 : Evaluation Reward 0.1 at step 1010, run 0
2019-09-28 17:52:13,658 : Average Reward 0.0009900990099009901 at step 1010, run 0
2019-09-28 17:52:13,660 : tderror_Q_U 0.0 at step 1010
2019-09-28 17:52:13,660 : tderror_Q_Omega 0.0 at step 1010
2019-09-28 17:52:13,665 : Reward 0.0
2019-09-28 17:52:13,665 : Evaluation Reward 0.0 at step 1020, run 0
2019-09-28 17:52:13,665 : Average Reward 0.0 at step 1020, run 0
2019-09-28 17:52:13,666 : tderror_Q_U 0.0 at step 1020
2019-09-28 17:52:13,666 : tderror_Q_Omega 0.0 at step 1020
2019-09-28 17:52:13,671 : Reward 0.0
2019-09-28 17:52:13,671 : Evaluation Reward 0.0 at step 1030, run 0
2019-09-28 17:52:13,671 : Average Reward 0.0 at step 1030, run 0
2019-09-28 17:52:13,672 : tderror_Q_U 0.0 at step 1030
2019-09-28 17:52:13,673 : tderror_Q_Omega 0.0 at step 1030
2019-09-28 17:52:13,677 : Reward 0.0
2019-09-28 17:52:13,677 : Evaluation Reward 0.0 at step 1040, run 0
2019-09-28 17:52:13,678 : Average Reward 0.0 at step 1040, run 0
2019-09-28 17:52:13,678 : tderror_Q_U 0.0 at step 1040
2019-09-28 17:52:13,679 : tderror_Q_Omega 0.0 at step 1040
2019-09-28 17:52:13,683 : Reward 0.0
2019-09-28 17:52:13,684 : Evaluation Reward 0.0 at step 1050, run 0
2019-09-28 17:52:13,684 : Average Reward 0.0 at step 1050, run 0
2019-09-28 17:52:13,685 : tderror_Q_U 0.0 at step 1050
2019-09-28 17:52:13,685 : tderror_Q_Omega 0.0 at step 1050
2019-09-28 17:52:13,689 : Reward 0.0
2019-09-28 17:52:13,690 : Evaluation Reward 0.0 at step 1060, run 0
2019-09-28 17:52:13,690 : Average Reward 0.0 at step 1060, run 0
2019-09-28 17:52:13,691 : tderror_Q_U 0.0 at step 1060
2019-09-28 17:52:13,691 : tderror_Q_Omega 0.0 at step 1060
2019-09-28 17:52:13,696 : Reward 0.0
2019-09-28 17:52:13,696 : Evaluation Reward 0.0 at step 1070, run 0
2019-09-28 17:52:13,696 : Average Reward 0.0 at step 1070, run 0
2019-09-28 17:52:13,697 : tderror_Q_U 0.0 at step 1070
2019-09-28 17:52:13,697 : tderror_Q_Omega 0.0 at step 1070
2019-09-28 17:52:13,701 : Reward 0.0
2019-09-28 17:52:13,702 : Evaluation Reward 0.0 at step 1080, run 0
2019-09-28 17:52:13,702 : Average Reward 0.0 at step 1080, run 0
2019-09-28 17:52:13,703 : tderror_Q_U 0.0 at step 1080
2019-09-28 17:52:13,703 : tderror_Q_Omega 0.0 at step 1080
2019-09-28 17:52:13,707 : Reward 0.0
2019-09-28 17:52:13,708 : Evaluation Reward 0.0 at step 1090, run 0
2019-09-28 17:52:13,708 : Average Reward 0.0 at step 1090, run 0
2019-09-28 17:52:13,709 : tderror_Q_U 0.0 at step 1090
2019-09-28 17:52:13,709 : tderror_Q_Omega 0.0 at step 1090
2019-09-28 17:52:13,713 : Reward 0.0
2019-09-28 17:52:13,714 : Evaluation Reward 0.0 at step 1100, run 0
2019-09-28 17:52:13,714 : Average Reward 0.0 at step 1100, run 0
2019-09-28 17:52:13,715 : tderror_Q_U 0.0 at step 1100
2019-09-28 17:52:13,715 : tderror_Q_Omega 0.0 at step 1100
2019-09-28 17:52:13,719 : Reward 0.0
2019-09-28 17:52:13,720 : Evaluation Reward 0.0 at step 1110, run 0
2019-09-28 17:52:13,720 : Average Reward 0.0 at step 1110, run 0
2019-09-28 17:52:13,720 : tderror_Q_U 0.0 at step 1110
2019-09-28 17:52:13,721 : tderror_Q_Omega 0.0 at step 1110
2019-09-28 17:52:13,725 : Reward 0.0
2019-09-28 17:52:13,726 : Evaluation Reward 0.0 at step 1120, run 0
2019-09-28 17:52:13,726 : Average Reward 0.0 at step 1120, run 0
2019-09-28 17:52:13,727 : tderror_Q_U 0.0 at step 1120
2019-09-28 17:52:13,727 : tderror_Q_Omega 0.0 at step 1120
2019-09-28 17:52:13,732 : Reward 0.0
2019-09-28 17:52:13,732 : Evaluation Reward 0.0 at step 1130, run 0
2019-09-28 17:52:13,732 : Average Reward 0.0 at step 1130, run 0
2019-09-28 17:52:13,733 : tderror_Q_U 0.0 at step 1130
2019-09-28 17:52:13,734 : tderror_Q_Omega 0.0 at step 1130
2019-09-28 17:52:13,738 : Reward 0.0
2019-09-28 17:52:13,739 : Evaluation Reward 0.0 at step 1140, run 0
2019-09-28 17:52:13,739 : Average Reward 0.0 at step 1140, run 0
2019-09-28 17:52:13,740 : tderror_Q_U 0.0 at step 1140
2019-09-28 17:52:13,740 : tderror_Q_Omega 0.0 at step 1140
2019-09-28 17:52:13,746 : Reward 0.0
2019-09-28 17:52:13,746 : Evaluation Reward 0.0 at step 1150, run 0
2019-09-28 17:52:13,746 : Average Reward 0.0 at step 1150, run 0
2019-09-28 17:52:13,747 : tderror_Q_U 0.0 at step 1150
2019-09-28 17:52:13,748 : tderror_Q_Omega 0.0 at step 1150
2019-09-28 17:52:13,752 : Reward 0.0
2019-09-28 17:52:13,753 : Evaluation Reward 0.0 at step 1160, run 0
2019-09-28 17:52:13,753 : Average Reward 0.0 at step 1160, run 0
2019-09-28 17:52:13,754 : tderror_Q_U 0.0 at step 1160
2019-09-28 17:52:13,754 : tderror_Q_Omega 0.0 at step 1160
2019-09-28 17:52:13,758 : Reward 0.0
2019-09-28 17:52:13,759 : Evaluation Reward 0.0 at step 1170, run 0
2019-09-28 17:52:13,759 : Average Reward 0.0 at step 1170, run 0
2019-09-28 17:52:13,760 : tderror_Q_U 0.0 at step 1170
2019-09-28 17:52:13,761 : tderror_Q_Omega 0.0 at step 1170
2019-09-28 17:52:13,766 : Reward 0.0
2019-09-28 17:52:13,766 : Evaluation Reward 0.0 at step 1180, run 0
2019-09-28 17:52:13,767 : Average Reward 0.0 at step 1180, run 0
2019-09-28 17:52:13,767 : tderror_Q_U 0.0 at step 1180
2019-09-28 17:52:13,768 : tderror_Q_Omega 0.0 at step 1180
2019-09-28 17:52:13,773 : Reward 0.0
2019-09-28 17:52:13,774 : Evaluation Reward 0.0 at step 1190, run 0
2019-09-28 17:52:13,774 : Average Reward 0.0 at step 1190, run 0
2019-09-28 17:52:13,776 : tderror_Q_U 0.0 at step 1190
2019-09-28 17:52:13,777 : tderror_Q_Omega 0.0 at step 1190
2019-09-28 17:52:13,781 : Reward 0.0
2019-09-28 17:52:13,781 : Evaluation Reward 0.0 at step 1200, run 0
2019-09-28 17:52:13,781 : Average Reward 0.0 at step 1200, run 0
2019-09-28 17:52:13,782 : tderror_Q_U 0.0 at step 1200
2019-09-28 17:52:13,782 : tderror_Q_Omega 0.0 at step 1200
2019-09-28 17:52:13,786 : Reward 0.0
2019-09-28 17:52:13,787 : Evaluation Reward 0.0 at step 1210, run 0
2019-09-28 17:52:13,787 : Average Reward 0.0 at step 1210, run 0
2019-09-28 17:52:13,788 : tderror_Q_U 0.0 at step 1210
2019-09-28 17:52:13,788 : tderror_Q_Omega 0.0 at step 1210
2019-09-28 17:52:13,792 : Reward 0.0
2019-09-28 17:52:13,793 : Evaluation Reward 0.0 at step 1220, run 0
2019-09-28 17:52:13,793 : Average Reward 0.0 at step 1220, run 0
2019-09-28 17:52:13,794 : tderror_Q_U 0.0 at step 1220
2019-09-28 17:52:13,794 : tderror_Q_Omega 0.0 at step 1220
2019-09-28 17:52:13,799 : Reward 0.0
2019-09-28 17:52:13,799 : Evaluation Reward 0.0 at step 1230, run 0
2019-09-28 17:52:13,799 : Average Reward 0.0 at step 1230, run 0
2019-09-28 17:52:13,800 : tderror_Q_U 0.0 at step 1230
2019-09-28 17:52:13,801 : tderror_Q_Omega 0.0 at step 1230
2019-09-28 17:52:13,805 : Reward 0.0
2019-09-28 17:52:13,806 : Evaluation Reward 0.0 at step 1240, run 0
2019-09-28 17:52:13,806 : Average Reward 0.0 at step 1240, run 0
2019-09-28 17:52:13,807 : tderror_Q_U 0.0 at step 1240
2019-09-28 17:52:13,807 : tderror_Q_Omega 0.0 at step 1240
2019-09-28 17:52:13,812 : Reward 0.0
2019-09-28 17:52:13,812 : Evaluation Reward 0.0 at step 1250, run 0
2019-09-28 17:52:13,812 : Average Reward 0.0 at step 1250, run 0
2019-09-28 17:52:13,813 : tderror_Q_U 0.0 at step 1250
2019-09-28 17:52:13,814 : tderror_Q_Omega 0.0 at step 1250
2019-09-28 17:52:13,818 : Reward 0.0
2019-09-28 17:52:13,818 : Evaluation Reward 0.0 at step 1260, run 0
2019-09-28 17:52:13,818 : Average Reward 0.0 at step 1260, run 0
2019-09-28 17:52:13,819 : tderror_Q_U 0.0 at step 1260
2019-09-28 17:52:13,819 : tderror_Q_Omega 0.0 at step 1260
2019-09-28 17:52:13,824 : Reward 0.0
2019-09-28 17:52:13,825 : Evaluation Reward 0.0 at step 1270, run 0
2019-09-28 17:52:13,825 : Average Reward 0.0 at step 1270, run 0
2019-09-28 17:52:13,826 : tderror_Q_U 0.0 at step 1270
2019-09-28 17:52:13,826 : tderror_Q_Omega 0.0 at step 1270
2019-09-28 17:52:13,830 : Reward 0.0
2019-09-28 17:52:13,831 : Evaluation Reward 0.0 at step 1280, run 0
2019-09-28 17:52:13,831 : Average Reward 0.0 at step 1280, run 0
2019-09-28 17:52:13,832 : tderror_Q_U 0.0 at step 1280
2019-09-28 17:52:13,832 : tderror_Q_Omega 0.0 at step 1280
2019-09-28 17:52:13,836 : Reward 0.0
2019-09-28 17:52:13,837 : Evaluation Reward 0.0 at step 1290, run 0
2019-09-28 17:52:13,837 : Average Reward 0.0 at step 1290, run 0
2019-09-28 17:52:13,838 : tderror_Q_U 0.0 at step 1290
2019-09-28 17:52:13,838 : tderror_Q_Omega 0.0 at step 1290
2019-09-28 17:52:13,842 : Reward 0.0
2019-09-28 17:52:13,843 : Evaluation Reward 0.0 at step 1300, run 0
2019-09-28 17:52:13,843 : Average Reward 0.0 at step 1300, run 0
2019-09-28 17:52:13,844 : tderror_Q_U 0.0 at step 1300
2019-09-28 17:52:13,844 : tderror_Q_Omega 0.0 at step 1300
2019-09-28 17:52:13,848 : Reward 0.0
2019-09-28 17:52:13,849 : Evaluation Reward 0.0 at step 1310, run 0
2019-09-28 17:52:13,849 : Average Reward 0.0 at step 1310, run 0
2019-09-28 17:52:13,850 : tderror_Q_U 0.0 at step 1310
2019-09-28 17:52:13,850 : tderror_Q_Omega 0.0 at step 1310
2019-09-28 17:52:13,854 : Reward 0.0
2019-09-28 17:52:13,855 : Evaluation Reward 0.0 at step 1320, run 0
2019-09-28 17:52:13,855 : Average Reward 0.0 at step 1320, run 0
2019-09-28 17:52:13,856 : tderror_Q_U 0.0 at step 1320
2019-09-28 17:52:13,856 : tderror_Q_Omega 0.0 at step 1320
2019-09-28 17:52:13,861 : Reward 0.0
2019-09-28 17:52:13,861 : Evaluation Reward 0.0 at step 1330, run 0
2019-09-28 17:52:13,861 : Average Reward 0.0 at step 1330, run 0
2019-09-28 17:52:13,862 : tderror_Q_U 0.0 at step 1330
2019-09-28 17:52:13,863 : tderror_Q_Omega 0.0 at step 1330
2019-09-28 17:52:13,866 : Reward 0.0
2019-09-28 17:52:13,867 : Evaluation Reward 0.0 at step 1340, run 0
2019-09-28 17:52:13,867 : Average Reward 0.0 at step 1340, run 0
2019-09-28 17:52:13,868 : tderror_Q_U 0.0 at step 1340
2019-09-28 17:52:13,868 : tderror_Q_Omega 0.0 at step 1340
2019-09-28 17:52:13,872 : Reward 0.0
2019-09-28 17:52:13,873 : Evaluation Reward 0.0 at step 1350, run 0
2019-09-28 17:52:13,873 : Average Reward 0.0 at step 1350, run 0
2019-09-28 17:52:13,874 : tderror_Q_U 0.0 at step 1350
2019-09-28 17:52:13,874 : tderror_Q_Omega 0.0 at step 1350
2019-09-28 17:52:13,880 : Reward 0.0
2019-09-28 17:52:13,880 : Evaluation Reward 0.0 at step 1360, run 0
2019-09-28 17:52:13,880 : Average Reward 0.0 at step 1360, run 0
2019-09-28 17:52:13,881 : tderror_Q_U 0.0 at step 1360
2019-09-28 17:52:13,881 : tderror_Q_Omega 0.0 at step 1360
2019-09-28 17:52:13,885 : Reward 0.0
2019-09-28 17:52:13,886 : Evaluation Reward 0.0 at step 1370, run 0
2019-09-28 17:52:13,886 : Average Reward 0.0 at step 1370, run 0
2019-09-28 17:52:13,887 : tderror_Q_U 0.0 at step 1370
2019-09-28 17:52:13,887 : tderror_Q_Omega 0.0 at step 1370
2019-09-28 17:52:13,891 : Reward 0.0
2019-09-28 17:52:13,892 : Evaluation Reward 0.0 at step 1380, run 0
2019-09-28 17:52:13,892 : Average Reward 0.0 at step 1380, run 0
2019-09-28 17:52:13,893 : tderror_Q_U 0.0 at step 1380
2019-09-28 17:52:13,893 : tderror_Q_Omega 0.0 at step 1380
2019-09-28 17:52:13,897 : Reward 0.0
2019-09-28 17:52:13,898 : Evaluation Reward 0.0 at step 1390, run 0
2019-09-28 17:52:13,898 : Average Reward 0.0 at step 1390, run 0
2019-09-28 17:52:13,898 : tderror_Q_U 0.0 at step 1390
2019-09-28 17:52:13,899 : tderror_Q_Omega 0.0 at step 1390
2019-09-28 17:52:13,903 : Reward 0.0
2019-09-28 17:52:13,904 : Evaluation Reward 0.0 at step 1400, run 0
2019-09-28 17:52:13,904 : Average Reward 0.0 at step 1400, run 0
2019-09-28 17:52:13,905 : tderror_Q_U 0.0 at step 1400
2019-09-28 17:52:13,905 : tderror_Q_Omega 0.0 at step 1400
2019-09-28 17:52:13,910 : Reward 0.0
2019-09-28 17:52:13,911 : Evaluation Reward 0.0 at step 1410, run 0
2019-09-28 17:52:13,911 : Average Reward 0.0 at step 1410, run 0
2019-09-28 17:52:13,912 : tderror_Q_U 0.0 at step 1410
2019-09-28 17:52:13,912 : tderror_Q_Omega 0.0 at step 1410
2019-09-28 17:52:13,916 : Reward 0.0
2019-09-28 17:52:13,916 : Evaluation Reward 0.0 at step 1420, run 0
2019-09-28 17:52:13,917 : Average Reward 0.0 at step 1420, run 0
2019-09-28 17:52:13,917 : tderror_Q_U 0.0 at step 1420
2019-09-28 17:52:13,918 : tderror_Q_Omega 0.0 at step 1420
2019-09-28 17:52:13,922 : Reward 0.0
2019-09-28 17:52:13,923 : Evaluation Reward 0.0 at step 1430, run 0
2019-09-28 17:52:13,923 : Average Reward 0.0 at step 1430, run 0
2019-09-28 17:52:13,923 : tderror_Q_U 0.0 at step 1430
2019-09-28 17:52:13,924 : tderror_Q_Omega 0.0 at step 1430
2019-09-28 17:52:13,928 : Reward 0.0
2019-09-28 17:52:13,929 : Evaluation Reward 0.0 at step 1440, run 0
2019-09-28 17:52:13,929 : Average Reward 0.0 at step 1440, run 0
2019-09-28 17:52:13,930 : tderror_Q_U 0.0 at step 1440
2019-09-28 17:52:13,930 : tderror_Q_Omega 0.0 at step 1440
2019-09-28 17:52:13,934 : Reward 0.0
2019-09-28 17:52:13,934 : Evaluation Reward 0.0 at step 1450, run 0
2019-09-28 17:52:13,934 : Average Reward 0.0 at step 1450, run 0
2019-09-28 17:52:13,935 : tderror_Q_U 0.0 at step 1450
2019-09-28 17:52:13,935 : tderror_Q_Omega 0.0 at step 1450
2019-09-28 17:52:13,940 : Reward 0.0
2019-09-28 17:52:13,940 : Evaluation Reward 0.0 at step 1460, run 0
2019-09-28 17:52:13,940 : Average Reward 0.0 at step 1460, run 0
2019-09-28 17:52:13,941 : tderror_Q_U 0.0 at step 1460
2019-09-28 17:52:13,941 : tderror_Q_Omega 0.0 at step 1460
2019-09-28 17:52:13,946 : Reward 0.0
2019-09-28 17:52:13,946 : Evaluation Reward 0.0 at step 1470, run 0
2019-09-28 17:52:13,946 : Average Reward 0.0 at step 1470, run 0
2019-09-28 17:52:13,947 : tderror_Q_U 0.0 at step 1470
2019-09-28 17:52:13,947 : tderror_Q_Omega 0.0 at step 1470
2019-09-28 17:52:13,952 : Reward 0.0
2019-09-28 17:52:13,952 : Evaluation Reward 0.0 at step 1480, run 0
2019-09-28 17:52:13,952 : Average Reward 0.0 at step 1480, run 0
2019-09-28 17:52:13,953 : tderror_Q_U 0.0 at step 1480
2019-09-28 17:52:13,953 : tderror_Q_Omega 0.0 at step 1480
2019-09-28 17:52:13,959 : Reward 0.0
2019-09-28 17:52:13,960 : Evaluation Reward 0.0 at step 1490, run 0
2019-09-28 17:52:13,960 : Average Reward 0.0 at step 1490, run 0
2019-09-28 17:52:13,961 : tderror_Q_U 0.0 at step 1490
2019-09-28 17:52:13,961 : tderror_Q_Omega 0.0 at step 1490
2019-09-28 17:52:13,965 : Reward 0.0
2019-09-28 17:52:13,966 : Evaluation Reward 0.0 at step 1500, run 0
2019-09-28 17:52:13,966 : Average Reward 0.0 at step 1500, run 0
2019-09-28 17:52:13,967 : tderror_Q_U 0.0 at step 1500
2019-09-28 17:52:13,967 : tderror_Q_Omega 0.0 at step 1500
2019-09-28 17:52:13,971 : Reward 0.0
2019-09-28 17:52:13,972 : Evaluation Reward 0.0 at step 1510, run 0
2019-09-28 17:52:13,972 : Average Reward 0.0 at step 1510, run 0
2019-09-28 17:52:13,973 : tderror_Q_U 0.0 at step 1510
2019-09-28 17:52:13,973 : tderror_Q_Omega 0.0 at step 1510
2019-09-28 17:52:13,978 : Reward 0.0
2019-09-28 17:52:13,978 : Evaluation Reward 0.0 at step 1520, run 0
2019-09-28 17:52:13,978 : Average Reward 0.0 at step 1520, run 0
2019-09-28 17:52:13,979 : tderror_Q_U 0.0 at step 1520
2019-09-28 17:52:13,979 : tderror_Q_Omega 0.0 at step 1520
2019-09-28 17:52:13,984 : Reward 0.0
2019-09-28 17:52:13,984 : Evaluation Reward 0.0 at step 1530, run 0
2019-09-28 17:52:13,984 : Average Reward 0.0 at step 1530, run 0
2019-09-28 17:52:13,985 : tderror_Q_U 0.0 at step 1530
2019-09-28 17:52:13,985 : tderror_Q_Omega 0.0 at step 1530
2019-09-28 17:52:13,990 : Reward 0.0
2019-09-28 17:52:13,990 : Evaluation Reward 0.0 at step 1540, run 0
2019-09-28 17:52:13,990 : Average Reward 0.0 at step 1540, run 0
2019-09-28 17:52:13,991 : tderror_Q_U 0.0 at step 1540
2019-09-28 17:52:13,991 : tderror_Q_Omega 0.0 at step 1540
2019-09-28 17:52:13,996 : Reward 0.0
2019-09-28 17:52:13,996 : Evaluation Reward 0.0 at step 1550, run 0
2019-09-28 17:52:13,996 : Average Reward 0.0 at step 1550, run 0
2019-09-28 17:52:13,997 : tderror_Q_U 0.0 at step 1550
2019-09-28 17:52:13,997 : tderror_Q_Omega 0.0 at step 1550
2019-09-28 17:52:14,002 : Reward 0.0
2019-09-28 17:52:14,002 : Evaluation Reward 0.0 at step 1560, run 0
2019-09-28 17:52:14,002 : Average Reward 0.0 at step 1560, run 0
2019-09-28 17:52:14,003 : tderror_Q_U 0.0 at step 1560
2019-09-28 17:52:14,003 : tderror_Q_Omega 0.0 at step 1560
2019-09-28 17:52:14,008 : Reward 0.0
2019-09-28 17:52:14,008 : Evaluation Reward 0.0 at step 1570, run 0
2019-09-28 17:52:14,008 : Average Reward 0.0 at step 1570, run 0
2019-09-28 17:52:14,009 : tderror_Q_U 0.0 at step 1570
2019-09-28 17:52:14,009 : tderror_Q_Omega 0.0 at step 1570
2019-09-28 17:52:14,014 : Reward 0.0
2019-09-28 17:52:14,014 : Evaluation Reward 0.0 at step 1580, run 0
2019-09-28 17:52:14,014 : Average Reward 0.0 at step 1580, run 0
2019-09-28 17:52:14,015 : tderror_Q_U 0.0 at step 1580
2019-09-28 17:52:14,015 : tderror_Q_Omega 0.0 at step 1580
2019-09-28 17:52:14,020 : Reward 0.0
2019-09-28 17:52:14,020 : Evaluation Reward 0.0 at step 1590, run 0
2019-09-28 17:52:14,020 : Average Reward 0.0 at step 1590, run 0
2019-09-28 17:52:14,021 : tderror_Q_U 0.0 at step 1590
2019-09-28 17:52:14,021 : tderror_Q_Omega 0.0 at step 1590
2019-09-28 17:52:14,026 : Reward 0.0
2019-09-28 17:52:14,026 : Evaluation Reward 0.0 at step 1600, run 0
2019-09-28 17:52:14,026 : Average Reward 0.0 at step 1600, run 0
2019-09-28 17:52:14,027 : tderror_Q_U 0.0 at step 1600
2019-09-28 17:52:14,027 : tderror_Q_Omega 0.0 at step 1600
2019-09-28 17:52:14,032 : Reward 0.0
2019-09-28 17:52:14,032 : Evaluation Reward 0.0 at step 1610, run 0
2019-09-28 17:52:14,033 : Average Reward 0.0 at step 1610, run 0
2019-09-28 17:52:14,033 : tderror_Q_U 0.0 at step 1610
2019-09-28 17:52:14,034 : tderror_Q_Omega 0.0 at step 1610
2019-09-28 17:52:14,038 : Reward 0.0
2019-09-28 17:52:14,038 : Evaluation Reward 0.0 at step 1620, run 0
2019-09-28 17:52:14,039 : Average Reward 0.0 at step 1620, run 0
2019-09-28 17:52:14,039 : tderror_Q_U 0.0 at step 1620
2019-09-28 17:52:14,040 : tderror_Q_Omega 0.0 at step 1620
2019-09-28 17:52:14,044 : Reward 0.0
2019-09-28 17:52:14,044 : Evaluation Reward 0.0 at step 1630, run 0
2019-09-28 17:52:14,045 : Average Reward 0.0 at step 1630, run 0
2019-09-28 17:52:14,045 : tderror_Q_U 0.0 at step 1630
2019-09-28 17:52:14,046 : tderror_Q_Omega 0.0 at step 1630
2019-09-28 17:52:14,050 : Reward 0.0
2019-09-28 17:52:14,051 : Evaluation Reward 0.0 at step 1640, run 0
2019-09-28 17:52:14,051 : Average Reward 0.0 at step 1640, run 0
2019-09-28 17:52:14,051 : tderror_Q_U 0.0 at step 1640
2019-09-28 17:52:14,052 : tderror_Q_Omega 0.0 at step 1640
2019-09-28 17:52:14,056 : Reward 0.0
2019-09-28 17:52:14,057 : Evaluation Reward 0.0 at step 1650, run 0
2019-09-28 17:52:14,057 : Average Reward 0.0 at step 1650, run 0
2019-09-28 17:52:14,057 : tderror_Q_U 0.0 at step 1650
2019-09-28 17:52:14,058 : tderror_Q_Omega 0.0 at step 1650
2019-09-28 17:52:14,063 : Reward 0.0
2019-09-28 17:52:14,063 : Evaluation Reward 0.0 at step 1660, run 0
2019-09-28 17:52:14,063 : Average Reward 0.0 at step 1660, run 0
2019-09-28 17:52:14,064 : tderror_Q_U 0.0 at step 1660
2019-09-28 17:52:14,064 : tderror_Q_Omega 0.0 at step 1660
2019-09-28 17:52:14,068 : Reward 0.0
2019-09-28 17:52:14,069 : Evaluation Reward 0.0 at step 1670, run 0
2019-09-28 17:52:14,069 : Average Reward 0.0 at step 1670, run 0
2019-09-28 17:52:14,069 : tderror_Q_U 0.0 at step 1670
2019-09-28 17:52:14,070 : tderror_Q_Omega 0.0 at step 1670
2019-09-28 17:52:14,075 : Reward 0.0
2019-09-28 17:52:14,076 : Evaluation Reward 0.0 at step 1680, run 0
2019-09-28 17:52:14,076 : Average Reward 0.0 at step 1680, run 0
2019-09-28 17:52:14,077 : tderror_Q_U 0.0 at step 1680
2019-09-28 17:52:14,077 : tderror_Q_Omega 0.0 at step 1680
2019-09-28 17:52:14,082 : Reward 0.0
2019-09-28 17:52:14,082 : Evaluation Reward 0.0 at step 1690, run 0
2019-09-28 17:52:14,082 : Average Reward 0.0 at step 1690, run 0
2019-09-28 17:52:14,083 : tderror_Q_U 0.0 at step 1690
2019-09-28 17:52:14,083 : tderror_Q_Omega 0.0 at step 1690
2019-09-28 17:52:14,088 : Reward 0.0
2019-09-28 17:52:14,088 : Evaluation Reward 0.0 at step 1700, run 0
2019-09-28 17:52:14,088 : Average Reward 0.0 at step 1700, run 0
2019-09-28 17:52:14,089 : tderror_Q_U 0.0 at step 1700
2019-09-28 17:52:14,089 : tderror_Q_Omega 0.0 at step 1700
2019-09-28 17:52:14,094 : Reward 0.0
2019-09-28 17:52:14,094 : Evaluation Reward 0.0 at step 1710, run 0
2019-09-28 17:52:14,094 : Average Reward 0.0 at step 1710, run 0
2019-09-28 17:52:14,095 : tderror_Q_U 0.0 at step 1710
2019-09-28 17:52:14,095 : tderror_Q_Omega 0.0 at step 1710
2019-09-28 17:52:14,099 : Reward 0.0
2019-09-28 17:52:14,100 : Evaluation Reward 0.0 at step 1720, run 0
2019-09-28 17:52:14,100 : Average Reward 0.0 at step 1720, run 0
2019-09-28 17:52:14,101 : tderror_Q_U 0.0 at step 1720
2019-09-28 17:52:14,101 : tderror_Q_Omega 0.0 at step 1720
2019-09-28 17:52:14,105 : Reward 0.0
2019-09-28 17:52:14,106 : Evaluation Reward 0.0 at step 1730, run 0
2019-09-28 17:52:14,106 : Average Reward 0.0 at step 1730, run 0
2019-09-28 17:52:14,107 : tderror_Q_U 0.0 at step 1730
2019-09-28 17:52:14,107 : tderror_Q_Omega 0.0 at step 1730
2019-09-28 17:52:14,112 : Reward 0.0
2019-09-28 17:52:14,112 : Evaluation Reward 0.0 at step 1740, run 0
2019-09-28 17:52:14,112 : Average Reward 0.0 at step 1740, run 0
2019-09-28 17:52:14,113 : tderror_Q_U 0.0 at step 1740
2019-09-28 17:52:14,113 : tderror_Q_Omega 0.0 at step 1740
2019-09-28 17:52:14,118 : Reward 0.0
2019-09-28 17:52:14,118 : Evaluation Reward 0.0 at step 1750, run 0
2019-09-28 17:52:14,119 : Average Reward 0.0 at step 1750, run 0
2019-09-28 17:52:14,119 : tderror_Q_U 0.0 at step 1750
2019-09-28 17:52:14,120 : tderror_Q_Omega 0.0 at step 1750
2019-09-28 17:52:14,124 : Reward 0.0
2019-09-28 17:52:14,124 : Evaluation Reward 0.0 at step 1760, run 0
2019-09-28 17:52:14,125 : Average Reward 0.0 at step 1760, run 0
2019-09-28 17:52:14,125 : tderror_Q_U 0.0 at step 1760
2019-09-28 17:52:14,126 : tderror_Q_Omega 0.0 at step 1760
2019-09-28 17:52:14,131 : Reward 0.0
2019-09-28 17:52:14,132 : Evaluation Reward 0.0 at step 1770, run 0
2019-09-28 17:52:14,132 : Average Reward 0.0 at step 1770, run 0
2019-09-28 17:52:14,132 : tderror_Q_U 0.0 at step 1770
2019-09-28 17:52:14,133 : tderror_Q_Omega 0.0 at step 1770
2019-09-28 17:52:14,137 : Reward 0.0
2019-09-28 17:52:14,137 : Evaluation Reward 0.0 at step 1780, run 0
2019-09-28 17:52:14,137 : Average Reward 0.0 at step 1780, run 0
2019-09-28 17:52:14,138 : tderror_Q_U 0.0 at step 1780
2019-09-28 17:52:14,139 : tderror_Q_Omega 0.0 at step 1780
2019-09-28 17:52:14,143 : Reward 0.0
2019-09-28 17:52:14,143 : Evaluation Reward 0.0 at step 1790, run 0
2019-09-28 17:52:14,143 : Average Reward 0.0 at step 1790, run 0
2019-09-28 17:52:14,144 : tderror_Q_U 0.0 at step 1790
2019-09-28 17:52:14,144 : tderror_Q_Omega 0.0 at step 1790
2019-09-28 17:52:14,149 : Reward 0.0
2019-09-28 17:52:14,149 : Evaluation Reward 0.0 at step 1800, run 0
2019-09-28 17:52:14,149 : Average Reward 0.0 at step 1800, run 0
2019-09-28 17:52:14,150 : tderror_Q_U 0.0 at step 1800
2019-09-28 17:52:14,150 : tderror_Q_Omega 0.0 at step 1800
2019-09-28 17:52:14,155 : Reward 0.0
2019-09-28 17:52:14,155 : Evaluation Reward 0.0 at step 1810, run 0
2019-09-28 17:52:14,156 : Average Reward 0.0 at step 1810, run 0
2019-09-28 17:52:14,157 : tderror_Q_U 0.0 at step 1810
2019-09-28 17:52:14,157 : tderror_Q_Omega 0.0 at step 1810
2019-09-28 17:52:14,161 : Reward 0.0
2019-09-28 17:52:14,162 : Evaluation Reward 0.0 at step 1820, run 0
2019-09-28 17:52:14,162 : Average Reward 0.0 at step 1820, run 0
2019-09-28 17:52:14,163 : tderror_Q_U 0.0 at step 1820
2019-09-28 17:52:14,163 : tderror_Q_Omega 0.0 at step 1820
2019-09-28 17:52:14,168 : Reward 0.0
2019-09-28 17:52:14,168 : Evaluation Reward 0.0 at step 1830, run 0
2019-09-28 17:52:14,169 : Average Reward 0.0 at step 1830, run 0
2019-09-28 17:52:14,169 : tderror_Q_U 0.0 at step 1830
2019-09-28 17:52:14,170 : tderror_Q_Omega 0.0 at step 1830
2019-09-28 17:52:14,174 : Reward 0.0
2019-09-28 17:52:14,174 : Evaluation Reward 0.0 at step 1840, run 0
2019-09-28 17:52:14,174 : Average Reward 0.0 at step 1840, run 0
2019-09-28 17:52:14,176 : tderror_Q_U 0.0 at step 1840
2019-09-28 17:52:14,177 : tderror_Q_Omega -0.5 at step 1840
2019-09-28 17:52:14,181 : Reward 0.0
2019-09-28 17:52:14,181 : Evaluation Reward 0.0 at step 1850, run 0
2019-09-28 17:52:14,182 : Average Reward 0.0 at step 1850, run 0
2019-09-28 17:52:14,182 : tderror_Q_U 0.0 at step 1850
2019-09-28 17:52:14,183 : tderror_Q_Omega 0.0 at step 1850
2019-09-28 17:52:14,187 : Reward 0.0
2019-09-28 17:52:14,187 : Evaluation Reward 0.0 at step 1860, run 0
2019-09-28 17:52:14,187 : Average Reward 0.0 at step 1860, run 0
2019-09-28 17:52:14,188 : tderror_Q_U 0.0 at step 1860
2019-09-28 17:52:14,188 : tderror_Q_Omega 0.0 at step 1860
2019-09-28 17:52:14,192 : Reward 0.0
2019-09-28 17:52:14,193 : Evaluation Reward 0.0 at step 1870, run 0
2019-09-28 17:52:14,193 : Average Reward 0.0 at step 1870, run 0
2019-09-28 17:52:14,194 : tderror_Q_U 0.0 at step 1870
2019-09-28 17:52:14,194 : tderror_Q_Omega 0.0 at step 1870
2019-09-28 17:52:14,199 : Reward 0.0
2019-09-28 17:52:14,200 : Evaluation Reward 0.0 at step 1880, run 0
2019-09-28 17:52:14,200 : Average Reward 0.0 at step 1880, run 0
2019-09-28 17:52:14,200 : tderror_Q_U 0.0 at step 1880
2019-09-28 17:52:14,201 : tderror_Q_Omega 0.0 at step 1880
2019-09-28 17:52:14,205 : Reward 0.0
2019-09-28 17:52:14,206 : Evaluation Reward 0.0 at step 1890, run 0
2019-09-28 17:52:14,206 : Average Reward 0.0 at step 1890, run 0
2019-09-28 17:52:14,206 : tderror_Q_U 0.0 at step 1890
2019-09-28 17:52:14,207 : tderror_Q_Omega 0.0 at step 1890
2019-09-28 17:52:14,211 : Reward 0.0
2019-09-28 17:52:14,212 : Evaluation Reward 0.0 at step 1900, run 0
2019-09-28 17:52:14,212 : Average Reward 0.0 at step 1900, run 0
2019-09-28 17:52:14,212 : tderror_Q_U 0.0 at step 1900
2019-09-28 17:52:14,213 : tderror_Q_Omega 0.0 at step 1900
2019-09-28 17:52:14,217 : Reward 0.0
2019-09-28 17:52:14,218 : Evaluation Reward 0.0 at step 1910, run 0
2019-09-28 17:52:14,218 : Average Reward 0.0 at step 1910, run 0
2019-09-28 17:52:14,218 : tderror_Q_U 0.0 at step 1910
2019-09-28 17:52:14,219 : tderror_Q_Omega 0.0 at step 1910
2019-09-28 17:52:14,223 : Reward 0.0
2019-09-28 17:52:14,224 : Evaluation Reward 0.0 at step 1920, run 0
2019-09-28 17:52:14,224 : Average Reward 0.0 at step 1920, run 0
2019-09-28 17:52:14,225 : tderror_Q_U 0.0 at step 1920
2019-09-28 17:52:14,225 : tderror_Q_Omega 0.0 at step 1920
2019-09-28 17:52:14,229 : Reward 1.0
2019-09-28 17:52:14,230 : Evaluation Reward 0.0 at step 1930, run 0
2019-09-28 17:52:14,230 : Average Reward 0.0 at step 1930, run 0
2019-09-28 17:52:14,230 : tderror_Q_U 0.5 at step 1930
2019-09-28 17:52:14,231 : tderror_Q_Omega 0.75 at step 1930
2019-09-28 17:52:14,231 : Average Duration of3.0805369127516764 for run 0
2019-09-28 17:52:14,232 : Option Switches are 447 for run 0
2019-09-28 17:52:14,233 : tderror_Q_U 0.0 at step 2000
2019-09-28 17:52:14,234 : tderror_Q_Omega 0.0 at step 2000
2019-09-28 17:52:14,239 : Reward 0.0
2019-09-28 17:52:14,239 : Evaluation Reward 0.1 at step 2010, run 0
2019-09-28 17:52:14,239 : Average Reward 0.0004975124378109452 at step 2010, run 0
2019-09-28 17:52:14,241 : tderror_Q_U 0.0 at step 2010
2019-09-28 17:52:14,241 : tderror_Q_Omega 0.0 at step 2010
2019-09-28 17:52:14,246 : Reward 0.0
2019-09-28 17:52:14,247 : Evaluation Reward 0.0 at step 2020, run 0
2019-09-28 17:52:14,247 : Average Reward 0.0 at step 2020, run 0
2019-09-28 17:52:14,248 : tderror_Q_U 0.0 at step 2020
2019-09-28 17:52:14,248 : tderror_Q_Omega 0.0 at step 2020
2019-09-28 17:52:14,252 : Reward 0.0
2019-09-28 17:52:14,253 : Evaluation Reward 0.0 at step 2030, run 0
2019-09-28 17:52:14,253 : Average Reward 0.0 at step 2030, run 0
2019-09-28 17:52:14,254 : tderror_Q_U 0.0 at step 2030
2019-09-28 17:52:14,254 : tderror_Q_Omega 0.0 at step 2030
2019-09-28 17:52:14,259 : Reward 0.0
2019-09-28 17:52:14,259 : Evaluation Reward 0.0 at step 2040, run 0
2019-09-28 17:52:14,260 : Average Reward 0.0 at step 2040, run 0
2019-09-28 17:52:14,260 : tderror_Q_U 0.0 at step 2040
2019-09-28 17:52:14,261 : tderror_Q_Omega 0.0 at step 2040
2019-09-28 17:52:14,265 : Reward 0.0
2019-09-28 17:52:14,266 : Evaluation Reward 0.0 at step 2050, run 0
2019-09-28 17:52:14,266 : Average Reward 0.0 at step 2050, run 0
2019-09-28 17:52:14,267 : tderror_Q_U 0.0 at step 2050
2019-09-28 17:52:14,267 : tderror_Q_Omega 0.0 at step 2050
2019-09-28 17:52:14,272 : Reward 0.0
2019-09-28 17:52:14,272 : Evaluation Reward 0.0 at step 2060, run 0
2019-09-28 17:52:14,273 : Average Reward 0.0 at step 2060, run 0
2019-09-28 17:52:14,273 : tderror_Q_U 0.0 at step 2060
2019-09-28 17:52:14,274 : tderror_Q_Omega 0.0 at step 2060
2019-09-28 17:52:14,279 : Reward 0.0
2019-09-28 17:52:14,279 : Evaluation Reward 0.0 at step 2070, run 0
2019-09-28 17:52:14,279 : Average Reward 0.0 at step 2070, run 0
2019-09-28 17:52:14,280 : tderror_Q_U 0.0 at step 2070
2019-09-28 17:52:14,281 : tderror_Q_Omega 0.0 at step 2070
2019-09-28 17:52:14,286 : Reward 0.0
2019-09-28 17:52:14,286 : Evaluation Reward 0.0 at step 2080, run 0
2019-09-28 17:52:14,287 : Average Reward 0.0 at step 2080, run 0
2019-09-28 17:52:14,288 : tderror_Q_U 0.0 at step 2080
2019-09-28 17:52:14,288 : tderror_Q_Omega 0.0 at step 2080
2019-09-28 17:52:14,292 : Reward 0.0
2019-09-28 17:52:14,293 : Evaluation Reward 0.0 at step 2090, run 0
2019-09-28 17:52:14,293 : Average Reward 0.0 at step 2090, run 0
2019-09-28 17:52:14,294 : tderror_Q_U 0.0 at step 2090
2019-09-28 17:52:14,294 : tderror_Q_Omega 0.0 at step 2090
2019-09-28 17:52:14,298 : Reward 0.0
2019-09-28 17:52:14,299 : Evaluation Reward 0.0 at step 2100, run 0
2019-09-28 17:52:14,299 : Average Reward 0.0 at step 2100, run 0
2019-09-28 17:52:14,299 : tderror_Q_U 0.0 at step 2100
2019-09-28 17:52:14,300 : tderror_Q_Omega 0.0 at step 2100
2019-09-28 17:52:14,304 : Reward 0.0
2019-09-28 17:52:14,304 : Evaluation Reward 0.0 at step 2110, run 0
2019-09-28 17:52:14,304 : Average Reward 0.0 at step 2110, run 0
2019-09-28 17:52:14,305 : tderror_Q_U 0.0 at step 2110
2019-09-28 17:52:14,305 : tderror_Q_Omega 0.0 at step 2110
2019-09-28 17:52:14,310 : Reward 0.0
2019-09-28 17:52:14,310 : Evaluation Reward 0.0 at step 2120, run 0
2019-09-28 17:52:14,311 : Average Reward 0.0 at step 2120, run 0
2019-09-28 17:52:14,311 : tderror_Q_U 0.0 at step 2120
2019-09-28 17:52:14,312 : tderror_Q_Omega 0.0 at step 2120
2019-09-28 17:52:14,316 : Reward 0.0
2019-09-28 17:52:14,316 : Evaluation Reward 0.0 at step 2130, run 0
2019-09-28 17:52:14,317 : Average Reward 0.0 at step 2130, run 0
2019-09-28 17:52:14,317 : tderror_Q_U 0.0 at step 2130
2019-09-28 17:52:14,318 : tderror_Q_Omega 0.0 at step 2130
2019-09-28 17:52:14,322 : Reward 0.0
2019-09-28 17:52:14,323 : Evaluation Reward 0.0 at step 2140, run 0
2019-09-28 17:52:14,323 : Average Reward 0.0 at step 2140, run 0
2019-09-28 17:52:14,324 : tderror_Q_U 0.0 at step 2140
2019-09-28 17:52:14,324 : tderror_Q_Omega 0.0 at step 2140
2019-09-28 17:52:14,329 : Reward 0.0
2019-09-28 17:52:14,329 : Evaluation Reward 0.0 at step 2150, run 0
2019-09-28 17:52:14,329 : Average Reward 0.0 at step 2150, run 0
2019-09-28 17:52:14,330 : tderror_Q_U 0.0 at step 2150
2019-09-28 17:52:14,330 : tderror_Q_Omega 0.0 at step 2150
2019-09-28 17:52:14,335 : Reward 0.0
2019-09-28 17:52:14,335 : Evaluation Reward 0.0 at step 2160, run 0
2019-09-28 17:52:14,335 : Average Reward 0.0 at step 2160, run 0
2019-09-28 17:52:14,336 : tderror_Q_U 0.0 at step 2160
2019-09-28 17:52:14,337 : tderror_Q_Omega 0.0 at step 2160
2019-09-28 17:52:14,341 : Reward 0.0
2019-09-28 17:52:14,342 : Evaluation Reward 0.0 at step 2170, run 0
2019-09-28 17:52:14,342 : Average Reward 0.0 at step 2170, run 0
2019-09-28 17:52:14,343 : tderror_Q_U 0.0 at step 2170
2019-09-28 17:52:14,344 : tderror_Q_Omega 0.0 at step 2170
2019-09-28 17:52:14,348 : Reward 0.0
2019-09-28 17:52:14,348 : Evaluation Reward 0.0 at step 2180, run 0
2019-09-28 17:52:14,349 : Average Reward 0.0 at step 2180, run 0
2019-09-28 17:52:14,349 : tderror_Q_U 0.0 at step 2180
2019-09-28 17:52:14,350 : tderror_Q_Omega 0.0 at step 2180
2019-09-28 17:52:14,354 : Reward 0.0
2019-09-28 17:52:14,354 : Evaluation Reward 0.0 at step 2190, run 0
2019-09-28 17:52:14,355 : Average Reward 0.0 at step 2190, run 0
2019-09-28 17:52:14,355 : tderror_Q_U 0.0 at step 2190
2019-09-28 17:52:14,356 : tderror_Q_Omega 0.0 at step 2190
2019-09-28 17:52:14,360 : Reward 0.0
2019-09-28 17:52:14,360 : Evaluation Reward 0.0 at step 2200, run 0
2019-09-28 17:52:14,360 : Average Reward 0.0 at step 2200, run 0
2019-09-28 17:52:14,361 : tderror_Q_U 0.0 at step 2200
2019-09-28 17:52:14,361 : tderror_Q_Omega 0.0 at step 2200
2019-09-28 17:52:14,366 : Reward 0.0
2019-09-28 17:52:14,366 : Evaluation Reward 0.0 at step 2210, run 0
2019-09-28 17:52:14,366 : Average Reward 0.0 at step 2210, run 0
2019-09-28 17:52:14,367 : tderror_Q_U 0.0 at step 2210
2019-09-28 17:52:14,368 : tderror_Q_Omega 0.0 at step 2210
2019-09-28 17:52:14,373 : Reward 0.0
2019-09-28 17:52:14,373 : Evaluation Reward 0.0 at step 2220, run 0
2019-09-28 17:52:14,373 : Average Reward 0.0 at step 2220, run 0
2019-09-28 17:52:14,375 : tderror_Q_U 0.0 at step 2220
2019-09-28 17:52:14,375 : tderror_Q_Omega 0.0 at step 2220
2019-09-28 17:52:14,380 : Reward 0.0
2019-09-28 17:52:14,381 : Evaluation Reward 0.0 at step 2230, run 0
2019-09-28 17:52:14,381 : Average Reward 0.0 at step 2230, run 0
2019-09-28 17:52:14,381 : tderror_Q_U 0.0 at step 2230
2019-09-28 17:52:14,382 : tderror_Q_Omega 0.0 at step 2230
2019-09-28 17:52:14,386 : Reward 0.0
2019-09-28 17:52:14,386 : Evaluation Reward 0.0 at step 2240, run 0
2019-09-28 17:52:14,387 : Average Reward 0.0 at step 2240, run 0
2019-09-28 17:52:14,388 : tderror_Q_U 0.0 at step 2240
2019-09-28 17:52:14,388 : tderror_Q_Omega 0.0 at step 2240
2019-09-28 17:52:14,392 : Reward 0.0
2019-09-28 17:52:14,393 : Evaluation Reward 0.0 at step 2250, run 0
2019-09-28 17:52:14,393 : Average Reward 0.0 at step 2250, run 0
2019-09-28 17:52:14,394 : tderror_Q_U 0.0 at step 2250
2019-09-28 17:52:14,394 : tderror_Q_Omega 0.0 at step 2250
2019-09-28 17:52:14,398 : Reward 0.0
2019-09-28 17:52:14,399 : Evaluation Reward 0.0 at step 2260, run 0
2019-09-28 17:52:14,399 : Average Reward 0.0 at step 2260, run 0
2019-09-28 17:52:14,400 : tderror_Q_U 0.0 at step 2260
2019-09-28 17:52:14,400 : tderror_Q_Omega 0.0 at step 2260
2019-09-28 17:52:14,404 : Reward 0.0
2019-09-28 17:52:14,405 : Evaluation Reward 0.0 at step 2270, run 0
2019-09-28 17:52:14,405 : Average Reward 0.0 at step 2270, run 0
2019-09-28 17:52:14,406 : tderror_Q_U 0.0 at step 2270
2019-09-28 17:52:14,406 : tderror_Q_Omega 0.0 at step 2270
2019-09-28 17:52:14,411 : Reward 0.0
2019-09-28 17:52:14,411 : Evaluation Reward 0.0 at step 2280, run 0
2019-09-28 17:52:14,411 : Average Reward 0.0 at step 2280, run 0
2019-09-28 17:52:14,412 : tderror_Q_U 0.0 at step 2280
2019-09-28 17:52:14,412 : tderror_Q_Omega 0.0 at step 2280
2019-09-28 17:52:14,417 : Reward 0.0
2019-09-28 17:52:14,417 : Evaluation Reward 0.0 at step 2290, run 0
2019-09-28 17:52:14,418 : Average Reward 0.0 at step 2290, run 0
2019-09-28 17:52:14,418 : tderror_Q_U 0.0 at step 2290
2019-09-28 17:52:14,419 : tderror_Q_Omega 0.0 at step 2290
2019-09-28 17:52:14,423 : Reward 0.0
2019-09-28 17:52:14,424 : Evaluation Reward 0.0 at step 2300, run 0
2019-09-28 17:52:14,424 : Average Reward 0.0 at step 2300, run 0
2019-09-28 17:52:14,425 : tderror_Q_U 0.0 at step 2300
2019-09-28 17:52:14,426 : tderror_Q_Omega 0.0 at step 2300
2019-09-28 17:52:14,431 : Reward 0.0
2019-09-28 17:52:14,431 : Evaluation Reward 0.0 at step 2310, run 0
2019-09-28 17:52:14,431 : Average Reward 0.0 at step 2310, run 0
2019-09-28 17:52:14,432 : tderror_Q_U 0.0 at step 2310
2019-09-28 17:52:14,432 : tderror_Q_Omega 0.0 at step 2310
2019-09-28 17:52:14,437 : Reward 0.0
2019-09-28 17:52:14,437 : Evaluation Reward 0.0 at step 2320, run 0
2019-09-28 17:52:14,437 : Average Reward 0.0 at step 2320, run 0
2019-09-28 17:52:14,438 : tderror_Q_U 0.0 at step 2320
2019-09-28 17:52:14,439 : tderror_Q_Omega 0.0 at step 2320
2019-09-28 17:52:14,443 : Reward 0.0
2019-09-28 17:52:14,443 : Evaluation Reward 0.0 at step 2330, run 0
2019-09-28 17:52:14,443 : Average Reward 0.0 at step 2330, run 0
2019-09-28 17:52:14,444 : tderror_Q_U 0.0 at step 2330
2019-09-28 17:52:14,445 : tderror_Q_Omega 0.0 at step 2330
2019-09-28 17:52:14,449 : Reward 0.0
2019-09-28 17:52:14,449 : Evaluation Reward 0.0 at step 2340, run 0
2019-09-28 17:52:14,450 : Average Reward 0.0 at step 2340, run 0
2019-09-28 17:52:14,450 : tderror_Q_U 0.0 at step 2340
2019-09-28 17:52:14,451 : tderror_Q_Omega 0.0 at step 2340
2019-09-28 17:52:14,456 : Reward 0.0
2019-09-28 17:52:14,456 : Evaluation Reward 0.0 at step 2350, run 0
2019-09-28 17:52:14,456 : Average Reward 0.0 at step 2350, run 0
2019-09-28 17:52:14,457 : tderror_Q_U 0.0 at step 2350
2019-09-28 17:52:14,457 : tderror_Q_Omega 0.0 at step 2350
2019-09-28 17:52:14,462 : Reward 0.0
2019-09-28 17:52:14,462 : Evaluation Reward 0.0 at step 2360, run 0
2019-09-28 17:52:14,463 : Average Reward 0.0 at step 2360, run 0
2019-09-28 17:52:14,463 : tderror_Q_U 0.0 at step 2360
2019-09-28 17:52:14,464 : tderror_Q_Omega 0.0 at step 2360
2019-09-28 17:52:14,469 : Reward 0.0
2019-09-28 17:52:14,469 : Evaluation Reward 0.0 at step 2370, run 0
2019-09-28 17:52:14,469 : Average Reward 0.0 at step 2370, run 0
2019-09-28 17:52:14,470 : tderror_Q_U 0.0 at step 2370
2019-09-28 17:52:14,470 : tderror_Q_Omega 0.0 at step 2370
2019-09-28 17:52:14,475 : Reward 0.0
2019-09-28 17:52:14,475 : Evaluation Reward 0.0 at step 2380, run 0
2019-09-28 17:52:14,475 : Average Reward 0.0 at step 2380, run 0
2019-09-28 17:52:14,476 : tderror_Q_U 0.0 at step 2380
2019-09-28 17:52:14,477 : tderror_Q_Omega 0.0 at step 2380
2019-09-28 17:52:14,481 : Reward 0.0
2019-09-28 17:52:14,481 : Evaluation Reward 0.0 at step 2390, run 0
2019-09-28 17:52:14,481 : Average Reward 0.0 at step 2390, run 0
2019-09-28 17:52:14,482 : tderror_Q_U 0.0 at step 2390
2019-09-28 17:52:14,482 : tderror_Q_Omega 0.0 at step 2390
2019-09-28 17:52:14,487 : Reward 0.0
2019-09-28 17:52:14,487 : Evaluation Reward 0.0 at step 2400, run 0
2019-09-28 17:52:14,487 : Average Reward 0.0 at step 2400, run 0
2019-09-28 17:52:14,488 : tderror_Q_U 0.0 at step 2400
2019-09-28 17:52:14,489 : tderror_Q_Omega 0.0 at step 2400
2019-09-28 17:52:14,493 : Reward 0.0
2019-09-28 17:52:14,494 : Evaluation Reward 0.0 at step 2410, run 0
2019-09-28 17:52:14,494 : Average Reward 0.0 at step 2410, run 0
2019-09-28 17:52:14,495 : tderror_Q_U 0.0 at step 2410
2019-09-28 17:52:14,495 : tderror_Q_Omega 0.0 at step 2410
2019-09-28 17:52:14,501 : Reward 0.0
2019-09-28 17:52:14,501 : Evaluation Reward 0.0 at step 2420, run 0
2019-09-28 17:52:14,501 : Average Reward 0.0 at step 2420, run 0
2019-09-28 17:52:14,502 : tderror_Q_U 0.0 at step 2420
2019-09-28 17:52:14,502 : tderror_Q_Omega 0.0 at step 2420
2019-09-28 17:52:14,507 : Reward 0.0
2019-09-28 17:52:14,507 : Evaluation Reward 0.0 at step 2430, run 0
2019-09-28 17:52:14,507 : Average Reward 0.0 at step 2430, run 0
2019-09-28 17:52:14,508 : tderror_Q_U 0.0 at step 2430
2019-09-28 17:52:14,509 : tderror_Q_Omega 0.0 at step 2430
2019-09-28 17:52:14,513 : Reward 0.0
2019-09-28 17:52:14,514 : Evaluation Reward 0.0 at step 2440, run 0
2019-09-28 17:52:14,514 : Average Reward 0.0 at step 2440, run 0
2019-09-28 17:52:14,514 : tderror_Q_U 0.0 at step 2440
2019-09-28 17:52:14,515 : tderror_Q_Omega 0.0 at step 2440
2019-09-28 17:52:14,519 : Reward 0.0
2019-09-28 17:52:14,520 : Evaluation Reward 0.0 at step 2450, run 0
2019-09-28 17:52:14,520 : Average Reward 0.0 at step 2450, run 0
2019-09-28 17:52:14,520 : tderror_Q_U 0.0 at step 2450
2019-09-28 17:52:14,521 : tderror_Q_Omega 0.0 at step 2450
2019-09-28 17:52:14,525 : Reward 0.0
2019-09-28 17:52:14,525 : Evaluation Reward 0.0 at step 2460, run 0
2019-09-28 17:52:14,526 : Average Reward 0.0 at step 2460, run 0
2019-09-28 17:52:14,526 : tderror_Q_U 0.0 at step 2460
2019-09-28 17:52:14,527 : tderror_Q_Omega 0.0 at step 2460
2019-09-28 17:52:14,531 : Reward 0.0
2019-09-28 17:52:14,532 : Evaluation Reward 0.0 at step 2470, run 0
2019-09-28 17:52:14,532 : Average Reward 0.0 at step 2470, run 0
2019-09-28 17:52:14,532 : tderror_Q_U 0.0 at step 2470
2019-09-28 17:52:14,533 : tderror_Q_Omega 0.0 at step 2470
2019-09-28 17:52:14,538 : Reward 0.0
2019-09-28 17:52:14,538 : Evaluation Reward 0.0 at step 2480, run 0
2019-09-28 17:52:14,538 : Average Reward 0.0 at step 2480, run 0
2019-09-28 17:52:14,539 : tderror_Q_U 0.0 at step 2480
2019-09-28 17:52:14,539 : tderror_Q_Omega 0.0 at step 2480
2019-09-28 17:52:14,543 : Reward 0.0
2019-09-28 17:52:14,543 : Evaluation Reward 0.0 at step 2490, run 0
2019-09-28 17:52:14,544 : Average Reward 0.0 at step 2490, run 0
2019-09-28 17:52:14,544 : tderror_Q_U 0.0 at step 2490
2019-09-28 17:52:14,545 : tderror_Q_Omega 0.0 at step 2490
2019-09-28 17:52:14,549 : Reward 0.0
2019-09-28 17:52:14,549 : Evaluation Reward 0.0 at step 2500, run 0
2019-09-28 17:52:14,549 : Average Reward 0.0 at step 2500, run 0
2019-09-28 17:52:14,550 : tderror_Q_U 0.0 at step 2500
2019-09-28 17:52:14,551 : tderror_Q_Omega 0.0 at step 2500
2019-09-28 17:52:14,555 : Reward 0.0
2019-09-28 17:52:14,555 : Evaluation Reward 0.0 at step 2510, run 0
2019-09-28 17:52:14,556 : Average Reward 0.0 at step 2510, run 0
2019-09-28 17:52:14,556 : tderror_Q_U 0.0 at step 2510
2019-09-28 17:52:14,557 : tderror_Q_Omega 0.0 at step 2510
2019-09-28 17:52:14,562 : Reward 0.0
2019-09-28 17:52:14,563 : Evaluation Reward 0.0 at step 2520, run 0
2019-09-28 17:52:14,563 : Average Reward 0.0 at step 2520, run 0
2019-09-28 17:52:14,564 : tderror_Q_U 0.0 at step 2520
2019-09-28 17:52:14,564 : tderror_Q_Omega 0.0 at step 2520
2019-09-28 17:52:14,569 : Reward 0.0
2019-09-28 17:52:14,569 : Evaluation Reward 0.0 at step 2530, run 0
2019-09-28 17:52:14,569 : Average Reward 0.0 at step 2530, run 0
2019-09-28 17:52:14,570 : tderror_Q_U 0.0 at step 2530
2019-09-28 17:52:14,570 : tderror_Q_Omega 0.0 at step 2530
2019-09-28 17:52:14,575 : Reward 0.0
2019-09-28 17:52:14,575 : Evaluation Reward 0.0 at step 2540, run 0
2019-09-28 17:52:14,575 : Average Reward 0.0 at step 2540, run 0
2019-09-28 17:52:14,576 : tderror_Q_U 0.0 at step 2540
2019-09-28 17:52:14,576 : tderror_Q_Omega 0.0 at step 2540
2019-09-28 17:52:14,582 : Reward 0.0
2019-09-28 17:52:14,583 : Evaluation Reward 0.0 at step 2550, run 0
2019-09-28 17:52:14,583 : Average Reward 0.0 at step 2550, run 0
2019-09-28 17:52:14,584 : tderror_Q_U 0.0 at step 2550
2019-09-28 17:52:14,584 : tderror_Q_Omega 0.0 at step 2550
2019-09-28 17:52:14,589 : Reward 0.0
2019-09-28 17:52:14,589 : Evaluation Reward 0.0 at step 2560, run 0
2019-09-28 17:52:14,589 : Average Reward 0.0 at step 2560, run 0
2019-09-28 17:52:14,590 : tderror_Q_U 0.0 at step 2560
2019-09-28 17:52:14,590 : tderror_Q_Omega 0.0 at step 2560
2019-09-28 17:52:14,595 : Reward 0.0
2019-09-28 17:52:14,595 : Evaluation Reward 0.0 at step 2570, run 0
2019-09-28 17:52:14,595 : Average Reward 0.0 at step 2570, run 0
2019-09-28 17:52:14,596 : tderror_Q_U 0.0 at step 2570
2019-09-28 17:52:14,596 : tderror_Q_Omega 0.0 at step 2570
2019-09-28 17:52:14,600 : Reward 0.0
2019-09-28 17:52:14,601 : Evaluation Reward 0.0 at step 2580, run 0
2019-09-28 17:52:14,601 : Average Reward 0.0 at step 2580, run 0
2019-09-28 17:52:14,602 : tderror_Q_U 0.0 at step 2580
2019-09-28 17:52:14,602 : tderror_Q_Omega 0.0 at step 2580
2019-09-28 17:52:14,606 : Reward 0.0
2019-09-28 17:52:14,606 : Evaluation Reward 0.0 at step 2590, run 0
2019-09-28 17:52:14,607 : Average Reward 0.0 at step 2590, run 0
2019-09-28 17:52:14,607 : tderror_Q_U 0.06125625 at step 2590
2019-09-28 17:52:14,607 : tderror_Q_Omega 0.06125625 at step 2590
2019-09-28 17:52:14,612 : Reward 0.0
2019-09-28 17:52:14,612 : Evaluation Reward 0.0 at step 2600, run 0
2019-09-28 17:52:14,613 : Average Reward 0.0 at step 2600, run 0
2019-09-28 17:52:14,613 : tderror_Q_U 0.0 at step 2600
2019-09-28 17:52:14,614 : tderror_Q_Omega 0.0 at step 2600
2019-09-28 17:52:14,619 : Reward 0.0
2019-09-28 17:52:14,619 : Evaluation Reward 0.0 at step 2610, run 0
2019-09-28 17:52:14,619 : Average Reward 0.0 at step 2610, run 0
2019-09-28 17:52:14,620 : tderror_Q_U 0.0018770619474005957 at step 2610
2019-09-28 17:52:14,620 : tderror_Q_Omega 0.0018770619474005957 at step 2610
2019-09-28 17:52:14,625 : Reward 0.0
2019-09-28 17:52:14,626 : Evaluation Reward 0.0 at step 2620, run 0
2019-09-28 17:52:14,626 : Average Reward 0.0 at step 2620, run 0
2019-09-28 17:52:14,627 : tderror_Q_U 0.00046457283198164743 at step 2620
2019-09-28 17:52:14,627 : tderror_Q_Omega -0.0014314493371098635 at step 2620
2019-09-28 17:52:14,632 : Reward 0.0
2019-09-28 17:52:14,632 : Evaluation Reward 0.0 at step 2630, run 0
2019-09-28 17:52:14,632 : Average Reward 0.0 at step 2630, run 0
2019-09-28 17:52:14,633 : tderror_Q_U 0.0 at step 2630
2019-09-28 17:52:14,633 : tderror_Q_Omega 0.0 at step 2630
2019-09-28 17:52:14,637 : Reward 0.0
2019-09-28 17:52:14,638 : Evaluation Reward 0.0 at step 2640, run 0
2019-09-28 17:52:14,638 : Average Reward 0.0 at step 2640, run 0
2019-09-28 17:52:14,639 : tderror_Q_U 0.0002153599507770627 at step 2640
2019-09-28 17:52:14,639 : tderror_Q_Omega 0.0002153599507770627 at step 2640
2019-09-28 17:52:14,644 : Reward 0.0
2019-09-28 17:52:14,644 : Evaluation Reward 0.0 at step 2650, run 0
2019-09-28 17:52:14,644 : Average Reward 0.0 at step 2650, run 0
2019-09-28 17:52:14,645 : tderror_Q_U 0.0 at step 2650
2019-09-28 17:52:14,645 : tderror_Q_Omega 0.0 at step 2650
2019-09-28 17:52:14,649 : Reward 0.0
2019-09-28 17:52:14,649 : Evaluation Reward 0.0 at step 2660, run 0
2019-09-28 17:52:14,650 : Average Reward 0.0 at step 2660, run 0
2019-09-28 17:52:14,650 : tderror_Q_U 0.0 at step 2660
2019-09-28 17:52:14,651 : tderror_Q_Omega 0.0 at step 2660
2019-09-28 17:52:14,655 : Reward 0.0
2019-09-28 17:52:14,655 : Evaluation Reward 0.0 at step 2670, run 0
2019-09-28 17:52:14,655 : Average Reward 0.0 at step 2670, run 0
2019-09-28 17:52:14,656 : tderror_Q_U 0.0 at step 2670
2019-09-28 17:52:14,657 : tderror_Q_Omega 0.0 at step 2670
2019-09-28 17:52:14,661 : Reward 0.0
2019-09-28 17:52:14,661 : Evaluation Reward 0.0 at step 2680, run 0
2019-09-28 17:52:14,661 : Average Reward 0.0 at step 2680, run 0
2019-09-28 17:52:14,662 : tderror_Q_U 0.0 at step 2680
2019-09-28 17:52:14,663 : tderror_Q_Omega 0.0 at step 2680
2019-09-28 17:52:14,668 : Reward 0.0
2019-09-28 17:52:14,668 : Evaluation Reward 0.0 at step 2690, run 0
2019-09-28 17:52:14,669 : Average Reward 0.0 at step 2690, run 0
2019-09-28 17:52:14,670 : tderror_Q_U 0.0 at step 2690
2019-09-28 17:52:14,670 : tderror_Q_Omega 0.0 at step 2690
2019-09-28 17:52:14,675 : Reward 0.0
2019-09-28 17:52:14,675 : Evaluation Reward 0.0 at step 2700, run 0
2019-09-28 17:52:14,675 : Average Reward 0.0 at step 2700, run 0
2019-09-28 17:52:14,676 : tderror_Q_U 9.327968434751456e-05 at step 2700
2019-09-28 17:52:14,676 : tderror_Q_Omega -0.0004536311766729325 at step 2700
2019-09-28 17:52:14,681 : Reward 0.0
2019-09-28 17:52:14,681 : Evaluation Reward 0.0 at step 2710, run 0
2019-09-28 17:52:14,681 : Average Reward 0.0 at step 2710, run 0
2019-09-28 17:52:14,682 : tderror_Q_U 0.0 at step 2710
2019-09-28 17:52:14,683 : tderror_Q_Omega 0.0 at step 2710
2019-09-28 17:52:14,688 : Reward 0.0
2019-09-28 17:52:14,688 : Evaluation Reward 0.0 at step 2720, run 0
2019-09-28 17:52:14,688 : Average Reward 0.0 at step 2720, run 0
2019-09-28 17:52:14,689 : tderror_Q_U 0.0 at step 2720
2019-09-28 17:52:14,689 : tderror_Q_Omega 0.0 at step 2720
2019-09-28 17:52:14,694 : Average Duration of2.9007832898172303 for run 0
2019-09-28 17:52:14,694 : Option Switches are 383 for run 0
2019-09-28 17:52:14,695 : tderror_Q_U 0.0 at step 3000
2019-09-28 17:52:14,696 : tderror_Q_Omega 0.0 at step 3000
2019-09-28 17:52:14,700 : Reward 0.0
2019-09-28 17:52:14,701 : Evaluation Reward 0.1 at step 3010, run 0
2019-09-28 17:52:14,701 : Average Reward 0.0003322259136212625 at step 3010, run 0
2019-09-28 17:52:14,702 : tderror_Q_U 0.0 at step 3010
2019-09-28 17:52:14,702 : tderror_Q_Omega 0.0 at step 3010
2019-09-28 17:52:14,707 : Reward 0.0
2019-09-28 17:52:14,707 : Evaluation Reward 0.0 at step 3020, run 0
2019-09-28 17:52:14,707 : Average Reward 0.0 at step 3020, run 0
2019-09-28 17:52:14,708 : tderror_Q_U 0.0 at step 3020
2019-09-28 17:52:14,708 : tderror_Q_Omega 0.0 at step 3020
2019-09-28 17:52:14,713 : Reward 0.0
2019-09-28 17:52:14,714 : Evaluation Reward 0.0 at step 3030, run 0
2019-09-28 17:52:14,714 : Average Reward 0.0 at step 3030, run 0
2019-09-28 17:52:14,715 : tderror_Q_U 0.0 at step 3030
2019-09-28 17:52:14,715 : tderror_Q_Omega 0.0 at step 3030
2019-09-28 17:52:14,719 : Reward 0.0
2019-09-28 17:52:14,720 : Evaluation Reward 0.0 at step 3040, run 0
2019-09-28 17:52:14,720 : Average Reward 0.0 at step 3040, run 0
2019-09-28 17:52:14,720 : tderror_Q_U 0.0 at step 3040
2019-09-28 17:52:14,721 : tderror_Q_Omega 0.0 at step 3040
2019-09-28 17:52:14,726 : Reward 0.0
2019-09-28 17:52:14,727 : Evaluation Reward 0.0 at step 3050, run 0
2019-09-28 17:52:14,727 : Average Reward 0.0 at step 3050, run 0
2019-09-28 17:52:14,728 : tderror_Q_U 0.0 at step 3050
2019-09-28 17:52:14,728 : tderror_Q_Omega 0.0 at step 3050
2019-09-28 17:52:14,732 : Reward 0.0
2019-09-28 17:52:14,733 : Evaluation Reward 0.0 at step 3060, run 0
2019-09-28 17:52:14,733 : Average Reward 0.0 at step 3060, run 0
2019-09-28 17:52:14,734 : tderror_Q_U 0.0 at step 3060
2019-09-28 17:52:14,734 : tderror_Q_Omega 0.0 at step 3060
2019-09-28 17:52:14,738 : Reward 0.0
2019-09-28 17:52:14,739 : Evaluation Reward 0.0 at step 3070, run 0
2019-09-28 17:52:14,739 : Average Reward 0.0 at step 3070, run 0
2019-09-28 17:52:14,740 : tderror_Q_U 0.0 at step 3070
2019-09-28 17:52:14,740 : tderror_Q_Omega 0.0 at step 3070
2019-09-28 17:52:14,744 : Reward 0.0
2019-09-28 17:52:14,745 : Evaluation Reward 0.0 at step 3080, run 0
2019-09-28 17:52:14,745 : Average Reward 0.0 at step 3080, run 0
2019-09-28 17:52:14,746 : tderror_Q_U 0.0 at step 3080
2019-09-28 17:52:14,746 : tderror_Q_Omega 0.0 at step 3080
2019-09-28 17:52:14,751 : Reward 0.0
2019-09-28 17:52:14,751 : Evaluation Reward 0.0 at step 3090, run 0
2019-09-28 17:52:14,751 : Average Reward 0.0 at step 3090, run 0
2019-09-28 17:52:14,752 : tderror_Q_U 0.0 at step 3090
2019-09-28 17:52:14,752 : tderror_Q_Omega 0.0 at step 3090
2019-09-28 17:52:14,757 : Reward 0.0
2019-09-28 17:52:14,758 : Evaluation Reward 0.0 at step 3100, run 0
2019-09-28 17:52:14,758 : Average Reward 0.0 at step 3100, run 0
2019-09-28 17:52:14,759 : tderror_Q_U 0.0 at step 3100
2019-09-28 17:52:14,759 : tderror_Q_Omega 0.0 at step 3100
2019-09-28 17:52:14,763 : Reward 0.0
2019-09-28 17:52:14,764 : Evaluation Reward 0.0 at step 3110, run 0
2019-09-28 17:52:14,764 : Average Reward 0.0 at step 3110, run 0
2019-09-28 17:52:14,765 : tderror_Q_U 0.0 at step 3110
2019-09-28 17:52:14,766 : tderror_Q_Omega 0.0 at step 3110
2019-09-28 17:52:14,770 : Reward 0.0
2019-09-28 17:52:14,771 : Evaluation Reward 0.0 at step 3120, run 0
2019-09-28 17:52:14,771 : Average Reward 0.0 at step 3120, run 0
2019-09-28 17:52:14,772 : tderror_Q_U 0.0 at step 3120
2019-09-28 17:52:14,772 : tderror_Q_Omega 0.0 at step 3120
2019-09-28 17:52:14,776 : Reward 0.0
2019-09-28 17:52:14,776 : Evaluation Reward 0.0 at step 3130, run 0
2019-09-28 17:52:14,776 : Average Reward 0.0 at step 3130, run 0
2019-09-28 17:52:14,777 : tderror_Q_U 0.0 at step 3130
2019-09-28 17:52:14,777 : tderror_Q_Omega 0.0 at step 3130
2019-09-28 17:52:14,781 : Reward 0.0
2019-09-28 17:52:14,781 : Evaluation Reward 0.0 at step 3140, run 0
2019-09-28 17:52:14,781 : Average Reward 0.0 at step 3140, run 0
2019-09-28 17:52:14,782 : tderror_Q_U 0.0 at step 3140
2019-09-28 17:52:14,783 : tderror_Q_Omega 0.0 at step 3140
2019-09-28 17:52:14,788 : Reward 0.0
2019-09-28 17:52:14,788 : Evaluation Reward 0.0 at step 3150, run 0
2019-09-28 17:52:14,788 : Average Reward 0.0 at step 3150, run 0
2019-09-28 17:52:14,790 : tderror_Q_U 0.0 at step 3150
2019-09-28 17:52:14,791 : tderror_Q_Omega 0.0 at step 3150
2019-09-28 17:52:14,796 : Reward 0.0
2019-09-28 17:52:14,796 : Evaluation Reward 0.0 at step 3160, run 0
2019-09-28 17:52:14,796 : Average Reward 0.0 at step 3160, run 0
2019-09-28 17:52:14,797 : tderror_Q_U 0.0 at step 3160
2019-09-28 17:52:14,798 : tderror_Q_Omega 0.0 at step 3160
2019-09-28 17:52:14,802 : Reward 0.0
2019-09-28 17:52:14,803 : Evaluation Reward 0.0 at step 3170, run 0
2019-09-28 17:52:14,803 : Average Reward 0.0 at step 3170, run 0
2019-09-28 17:52:14,804 : tderror_Q_U 0.0 at step 3170
2019-09-28 17:52:14,804 : tderror_Q_Omega 0.0 at step 3170
2019-09-28 17:52:14,810 : Reward 0.0
2019-09-28 17:52:14,811 : Evaluation Reward 0.0 at step 3180, run 0
2019-09-28 17:52:14,811 : Average Reward 0.0 at step 3180, run 0
2019-09-28 17:52:14,812 : tderror_Q_U 0.0 at step 3180
2019-09-28 17:52:14,812 : tderror_Q_Omega 0.0 at step 3180
2019-09-28 17:52:14,816 : Reward 0.0
2019-09-28 17:52:14,816 : Evaluation Reward 0.0 at step 3190, run 0
2019-09-28 17:52:14,816 : Average Reward 0.0 at step 3190, run 0
2019-09-28 17:52:14,817 : tderror_Q_U 0.0 at step 3190
2019-09-28 17:52:14,818 : tderror_Q_Omega 0.0 at step 3190
2019-09-28 17:52:14,823 : Reward 0.0
2019-09-28 17:52:14,823 : Evaluation Reward 0.0 at step 3200, run 0
2019-09-28 17:52:14,823 : Average Reward 0.0 at step 3200, run 0
2019-09-28 17:52:14,825 : tderror_Q_U 0.0 at step 3200
2019-09-28 17:52:14,825 : tderror_Q_Omega 0.0 at step 3200
2019-09-28 17:52:14,830 : Reward 0.0
2019-09-28 17:52:14,831 : Evaluation Reward 0.0 at step 3210, run 0
2019-09-28 17:52:14,831 : Average Reward 0.0 at step 3210, run 0
2019-09-28 17:52:14,832 : tderror_Q_U 0.0 at step 3210
2019-09-28 17:52:14,832 : tderror_Q_Omega 0.0 at step 3210
2019-09-28 17:52:14,840 : Reward 0.0
2019-09-28 17:52:14,841 : Evaluation Reward 0.0 at step 3220, run 0
2019-09-28 17:52:14,841 : Average Reward 0.0 at step 3220, run 0
2019-09-28 17:52:14,842 : tderror_Q_U 0.0 at step 3220
2019-09-28 17:52:14,842 : tderror_Q_Omega 0.0 at step 3220
2019-09-28 17:52:14,846 : Reward 0.0
2019-09-28 17:52:14,847 : Evaluation Reward 0.0 at step 3230, run 0
2019-09-28 17:52:14,847 : Average Reward 0.0 at step 3230, run 0
2019-09-28 17:52:14,848 : tderror_Q_U 0.0 at step 3230
2019-09-28 17:52:14,849 : tderror_Q_Omega 0.0 at step 3230
